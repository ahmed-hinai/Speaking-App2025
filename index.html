<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Speaking Practice – Unit 1</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      margin: 0;
      padding: 16px;
      background: #f4f4f8;
      color: #222;
    }

    .app {
      max-width: 600px;
      margin: 0 auto;
      background: #ffffff;
      border-radius: 16px;
      padding: 20px;
      box-shadow: 0 4px 10px rgba(0,0,0,0.08);
    }

    h1 {
      font-size: 1.5rem;
      margin-bottom: 4px;
    }

    h2 {
      font-size: 1.1rem;
      margin-top: 0;
      color: #555;
    }

    .meta-row {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 12px;
    }

    .meta-row label {
      font-size: 0.85rem;
      display: flex;
      flex-direction: column;
      gap: 4px;
      flex: 1;
      min-width: 120px;
    }

    input[type="text"] {
      padding: 6px 8px;
      border-radius: 8px;
      border: 1px solid #ccc;
      font-size: 0.9rem;
    }

    .prompt-selector {
      display: flex;
      gap: 8px;
      margin: 12px 0;
      flex-wrap: wrap;
    }

    .prompt-btn {
      flex: 1;
      min-width: 70px;
      padding: 8px 10px;
      border-radius: 999px;
      border: 1px solid #ccc;
      background: #f0f0f5;
      font-size: 0.9rem;
      cursor: pointer;
    }

    .prompt-btn.active {
      background: #2563eb;
      color: white;
      border-color: #2563eb;
    }

    .prompt-text {
      background: #fafafa;
      border-radius: 12px;
      padding: 10px 12px;
      border: 1px solid #e0e0e0;
      font-size: 0.95rem;
      line-height: 1.4;
      margin-bottom: 16px;
    }

    .controls {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 12px;
    }

    button {
      border: none;
      border-radius: 999px;
      padding: 10px 14px;
      font-size: 0.95rem;
      cursor: pointer;
    }

    .record {
      background: #dc2626;
      color: white;
      flex: 1;
      min-width: 140px;
    }

    .stop {
      background: #fbbf24;
      color: #222;
      flex: 1;
      min-width: 140px;
    }

    .play {
      background: #16a34a;
      color: white;
      flex: 1;
      min-width: 140px;
    }

    .upload {
      background: #2563eb;
      color: white;
      flex: 1;
      min-width: 140px;
    }
    .feedback {
      background: #7600FC;
      color: white;
      flex: 1;
      min-width: 140px;
    }
    .feedback-text {
      background: #fafafa;
      border-radius: 12px;
      padding: 10px 12px;
      border: 1px solid #e0e0e0;
      font-size: 0.95rem;
      line-height: 1.4;
      margin-top: 16px;
      margin-bottom: 16px;
    }

    .disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }

    .timer {
      font-family: "SF Mono", Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 1rem;
      margin-bottom: 8px;
    }

    .status {
      font-size: 0.85rem;
      color: #555;
      min-height: 1.2em;
      margin-top: 4px;
    }

    audio {
      width: 100%;
      margin-top: 8px;
    }

    .footer {
      margin-top: 16px;
      font-size: 0.75rem;
      color: #777;
    }
  </style>
</head>
<body>
  <div class="app">
    <h1>Speaking Practice – Unit 1</h1>
    <h2>Animals – Endangered species & comparisons</h2>

    <div class="meta-row">
      <label>
        Student ID
        <input type="text" id="studentId" placeholder="e.g. 2412345" />
      </label>
      <label>
        Class Code
        <input type="text" id="classCode" value="E423" />
    </div>

    <div class="prompt-selector">
      <button class="prompt-btn active" data-prompt="1">Prompt 1</button>
      <button class="prompt-btn" data-prompt="2">Prompt 2</button>
      <button class="prompt-btn" data-prompt="3">Prompt 3</button>
    </div>

    <div id="promptText" class="prompt-text">
      Talk about an endangered animal. Say:
      • where it lives  
      • why it is at risk  
      • what people can do to protect it.
    </div>

    <div class="timer">
      Time: <span id="timerDisplay">00:00</span>
    </div>

    <div class="controls">
      <button id="recordBtn" class="record">Start Recording</button>
      <button id="stopBtn" class="stop disabled">Stop</button>
    </div>

    <button id="playBtn" class="play disabled">Play Recording</button>
    <audio id="audioPlayer" controls style="display:none;"></audio>

    <button id="uploadBtn" class="upload disabled">Download Audio</button>
    <button id="feedbackBtn" class="feedback disabled">Assess Recording</button>
    <div id="feedbackText" class="feedback-text"></div>
    <div id="status" class="status"></div>


    <div class="footer">
      Your recording, unit, prompt number, student ID, class code, and time will be sent securely to your teacher.
    </div>
  </div>

  <script>
// ====== CONFIG ======
const WEBHOOK_URL = "https://hook.eu2.make.com/mgiljprq2kdwb4my635a32iq5xwllgv8";
const UNIT_NAME = "Unit 1";

const prompts = {
  1: "Talk about an endangered animal. Say:\n• where it lives\n• why it is at risk\n• what people can do to protect it.",
  2: "Talk about your favourite animal. Say:\n• what it looks like\n• where it lives\n• what it eats\n• why you like it.",
  3: "Compare two animals (for example, a lion and a camel). Say:\n• how they are similar\n• how they are different\n• which one you prefer and why."
};

// ====== DOM ELEMENTS ======
const promptButtons = document.querySelectorAll(".prompt-btn");
const promptTextEl = document.getElementById("promptText");
const timerDisplay = document.getElementById("timerDisplay");
const recordBtn = document.getElementById("recordBtn");
const stopBtn = document.getElementById("stopBtn");
const playBtn = document.getElementById("playBtn");
const uploadBtn = document.getElementById("uploadBtn");
const feedbackBtn = document.getElementById("feedbackBtn");
const feedbackText = document.getElementById("feedbackText");
const statusEl = document.getElementById("status");
const studentIdInput = document.getElementById("studentId");
const classCodeInput = document.getElementById("classCode");
const audioPlayer = document.getElementById("audioPlayer");

// ====== STATE ======
let currentPrompt = 1;
let mediaRecorder = null;
let audioChunks = [];
let timerInterval = null;
let seconds = 0;
let recordedBlob = null;

// ====== PROMPT HANDLING ======
function setPrompt(promptNumber) {
  currentPrompt = promptNumber;
  promptButtons.forEach(btn => {
    btn.classList.toggle("active", Number(btn.dataset.prompt) === promptNumber);
  });
  promptTextEl.textContent = prompts[promptNumber];
}

promptButtons.forEach(btn => {
  btn.addEventListener("click", () => {
    const p = Number(btn.dataset.prompt);
    setPrompt(p);
  });
});

// ====== TIMER ======
function startTimer() {
  seconds = 0;
  updateTimerDisplay();
  timerInterval = setInterval(() => {
    seconds++;
    updateTimerDisplay();
  }, 1000);
}

function stopTimer() {
  if (timerInterval) {
    clearInterval(timerInterval);
    timerInterval = null;
  }
}

function updateTimerDisplay() {
  const mins = String(Math.floor(seconds / 60)).padStart(2, "0");
  const secs = String(seconds % 60).padStart(2, "0");
  timerDisplay.textContent = `${mins}:${secs}`;
}

// ====== RECORDING ======
async function startRecording() {
  statusEl.textContent = "Requesting microphone access...";
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    
    // Try to use a more compatible format
    const options = { 
      audioBitsPerSecond: 128000,
      mimeType: 'audio/webm;codecs=opus'
    };
    
    // Fallback if opus isn't supported
    if (!MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
      options.mimeType = 'audio/webm';
    }
    
    mediaRecorder = new MediaRecorder(stream, options);
    audioChunks = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    mediaRecorder.onstart = () => {
      statusEl.textContent = "Recording... speak now.";
      recordBtn.classList.add("disabled");
      recordBtn.disabled = true;

      stopBtn.classList.remove("disabled");
      stopBtn.disabled = false;

      playBtn.classList.add("disabled");
      playBtn.disabled = true;

      uploadBtn.classList.add("disabled");
      uploadBtn.disabled = true;
      feedbackBtn.classList.add("disabled");
      feedbackBtn.disabled = true;

      startTimer();
    };

    mediaRecorder.onstop = () => {
      stopTimer();
      recordedBlob = new Blob(audioChunks, { type: options.mimeType });
      const audioURL = URL.createObjectURL(recordedBlob);
      audioPlayer.src = audioURL;
      audioPlayer.style.display = "block";

      statusEl.textContent = "Recording finished.";

      playBtn.classList.remove("disabled");
      playBtn.disabled = false;

      uploadBtn.classList.remove("disabled");
      uploadBtn.disabled = false;
      feedbackBtn.classList.remove("disabled");
      feedbackBtn.disabled = false;
      recordBtn.classList.remove("disabled");
      recordBtn.disabled = false;
    };

    mediaRecorder.start();
  } catch (err) {
    console.error(err);
    statusEl.textContent = "Microphone error. Please allow access in your browser settings.";
  }
}

function stopRecording() {
  if (mediaRecorder && mediaRecorder.state === "recording") {
    mediaRecorder.stop();
    mediaRecorder.stream.getTracks().forEach(track => track.stop()); // Stop the stream tracks
    stopBtn.classList.add("disabled");
    stopBtn.disabled = true;
    statusEl.textContent = "Stopping...";
  }
}

// ====== PLAYBACK ======
function playRecording() {
  if (!recordedBlob) {
    statusEl.textContent = "No recording yet.";
    return;
  }
  audioPlayer.play().catch(err => {
    console.error(err);
    statusEl.textContent = "Cannot play audio. Try again.";
  });
}

// ====== DOWNLOAD ======
async function uploadRecording() {
  if (!recordedBlob) {
    statusEl.textContent = "Please record something first.";
    return;
  }

  const studentId = studentIdInput.value.trim() || "anonymous";
  const classCode = classCodeInput.value.trim() || "unknown";
  const now = new Date();

  const y = now.getFullYear();
  const m = String(now.getMonth() + 1).padStart(2, "0");
  const d = String(now.getDate()).padStart(2, "0");
  const hh = String(now.getHours()).padStart(2, "0");
  const mm = String(now.getMinutes()).padStart(2, "0");
  const ss = String(now.getSeconds()).padStart(2, "0");

  const filename = `${studentId}_U1_P${currentPrompt}_${y}${m}${d}_${hh}${mm}${ss}.webm`;

  try {
    const url = URL.createObjectURL(recordedBlob);
    const a = document.createElement('a');
    a.style.display = 'none';
    a.href = url;
    a.download = filename;
    document.body.appendChild(a);
    a.click();

    setTimeout(() => {
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
    }, 100);
    
    const googleDriveFolderUrl = "https://drive.google.com/drive/folders/1Vhk_9L1Cbbyedz4TZULG74alHmfzpwhK";
    window.open(googleDriveFolderUrl, '_blank');

    statusEl.textContent = "Downloaded successfully. Please upload the audio file to your teacher's Google Drive.";
  } catch (err) {
    console.error(err);
    statusEl.textContent = "Download error. Please try again later.";
  }
}

// ====== ANALYSIS ======
feedbackBtn.addEventListener("click", analyzeRecording);

async function analyzeRecording() {
  if (!recordedBlob) {
    statusEl.textContent = "Please record something first.";
    return;
  }

  feedbackText.textContent = "Analyzing your speech...";
  feedbackBtn.disabled = true;
  statusEl.textContent = "Processing audio...";

  try {
    // Convert WebM to WAV format
    const wavBlob = await convertWebMToWAV(recordedBlob);
    
    console.log("Converted audio:", {
      originalType: recordedBlob.type,
      convertedType: wavBlob.type,
      originalSize: recordedBlob.size,
      convertedSize: wavBlob.size
    });

    const formData = new FormData();
    formData.append("audio", wavBlob, "recording.wav");

    // Add timeout to the fetch request
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 60000); // 60 second timeout

    const response = await fetch("https://speaking-app2025.onrender.com/analyze", {
      method: "POST",
      body: formData,
      signal: controller.signal
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      let errorText;
      try {
        errorText = await response.text();
      } catch (e) {
        errorText = 'Could not read error response';
      }
      throw new Error(`Server error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    
    if (data.feedback) {
      feedbackText.textContent = data.feedback;
      statusEl.textContent = "Analysis complete!";
    } else if (data.error) {
      feedbackText.textContent = "Error: " + data.error;
      statusEl.textContent = "Analysis failed.";
    } else {
      feedbackText.textContent = "Unexpected response from server.";
      statusEl.textContent = "Analysis failed.";
    }

  } catch (err) {
    console.error('Analysis error:', err);
    if (err.name === 'AbortError') {
      feedbackText.textContent = "Request timed out. Please try again.";
      statusEl.textContent = "Timeout error.";
    } else {
      feedbackText.textContent = "Error analyzing audio: " + err.message;
      statusEl.textContent = "Analysis error.";
    }
  }

  feedbackBtn.disabled = false;
}

// Convert WebM blob to WAV format using Web Audio API
async function convertWebMToWAV(webmBlob) {
  return new Promise((resolve, reject) => {
    // Create an audio context
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    
    // Create file reader to read the WebM blob
    const fileReader = new FileReader();
    
    fileReader.onload = function() {
      const arrayBuffer = this.result;
      
      // Decode the WebM audio data
      audioContext.decodeAudioData(arrayBuffer, (audioBuffer) => {
        // Convert the AudioBuffer to WAV format
        const wavBlob = audioBufferToWav(audioBuffer);
        resolve(wavBlob);
      }, (error) => {
        console.error('Error decoding audio:', error);
        // Fallback: create a blob with WAV type but same content
        const fallbackBlob = new Blob([webmBlob], { type: 'audio/wav' });
        resolve(fallbackBlob);
      });
    };
    
    fileReader.onerror = () => {
      // Fallback if conversion fails
      const fallbackBlob = new Blob([webmBlob], { type: 'audio/wav' });
      resolve(fallbackBlob);
    };
    
    fileReader.readAsArrayBuffer(webmBlob);
  });
}

// Convert AudioBuffer to WAV Blob
function audioBufferToWav(audioBuffer) {
  const numChannels = audioBuffer.numberOfChannels;
  const sampleRate = audioBuffer.sampleRate;
  const length = audioBuffer.length;
  
  // Create WAV header
  const wavBuffer = new ArrayBuffer(44 + length * numChannels * 2);
  const view = new DataView(wavBuffer);
  
  // RIFF identifier
  writeString(view, 0, 'RIFF');
  // RIFF chunk length
  view.setUint32(4, 36 + length * numChannels * 2, true);
  // RIFF type
  writeString(view, 8, 'WAVE');
  // format chunk identifier
  writeString(view, 12, 'fmt ');
  // format chunk length
  view.setUint32(16, 16, true);
  // sample format (raw)
  view.setUint16(20, 1, true);
  // channel count
  view.setUint16(22, numChannels, true);
  // sample rate
  view.setUint32(24, sampleRate, true);
  // byte rate (sample rate * block align)
  view.setUint32(28, sampleRate * numChannels * 2, true);
  // block align (channel count * bytes per sample)
  view.setUint16(32, numChannels * 2, true);
  // bits per sample
  view.setUint16(34, 16, true);
  // data chunk identifier
  writeString(view, 36, 'data');
  // data chunk length
  view.setUint32(40, length * numChannels * 2, true);
  
  // Write the PCM samples
  const offset = 44;
  for (let i = 0; i < length; i++) {
    for (let channel = 0; channel < numChannels; channel++) {
      const sample = Math.max(-1, Math.min(1, audioBuffer.getChannelData(channel)[i]));
      view.setInt16(offset + (i * numChannels + channel) * 2, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
    }
  }
  
  return new Blob([wavBuffer], { type: 'audio/wav' });
}

function writeString(view, offset, string) {
  for (let i = 0; i < string.length; i++) {
    view.setUint8(offset + i, string.charCodeAt(i));
  }
}

// ====== EVENT LISTENERS ======
recordBtn.addEventListener("click", startRecording);
stopBtn.addEventListener("click", stopRecording);
playBtn.addEventListener("click", playRecording);
uploadBtn.addEventListener("click", uploadRecording);
</script>





